# ğŸš€ Projeto Terraform + Ansible + Proxmox + Kubernetes + Rancher

## ğŸ“‹ Resumo do Projeto

Est### ğŸ·ï¸ Tags Aplicadas
```
environment=production
project=my-k8s-cluster  
managed-by=terraform
kubernetes + master/worker
node-type=control-plane/worker
```o provisiona automaticamente um cluster Kubernetes completo no Proxmox VE com Rancher para gerenciamento, usando a combinaÃ§Ã£o de Terraform para infraestrutura e Ansible para configuraÃ§Ã£o, seguindo as melhores prÃ¡ticas de seguranÃ§a e organizaÃ§Ã£o.

## ï¿½ VersÃ£o Atual: **v2.0** - Enterprise Ready

### âœ¨ **Novidades v2.0**
- ğŸ” **SSH Key Authentication** exclusivo
- ğŸ·ï¸ **Tags padronizadas** para gestÃ£o
- âœ… **ValidaÃ§Ãµes robustas** de configuraÃ§Ã£o
- ğŸ“Š **Outputs informativos** e seguros
- ğŸ›¡ï¸ **PrÃ¡ticas de seguranÃ§a** aprimoradas

## ğŸ—ï¸ **Arquitetura e Componentes**

### ğŸ“ **Diagrama de Arquitetura**

```mermaid
graph TB
    subgraph "ğŸ–¥ï¸ EstaÃ§Ã£o de Trabalho"
        DEV[Desenvolvedor/Administrador]
        TF[Terraform]
        AN[Ansible]
    end
    
    subgraph "ğŸ¢ Proxmox VE Cluster - CEFETES"
        PVE[cacto.cefetes.br:8006<br/>Node: gardenia]
        
        subgraph "ğŸ§ Ubuntu 22.04 Template"
            TPL[ubuntu-22.04-cloud<br/>Template base]
        end
        
        subgraph "â˜¸ï¸ Kubernetes Cluster"
            direction TB
            M1[ğŸ¯ Master Node<br/>172.17.176.34<br/>4 vCPU, 8GB RAM, 80GB]
            W1[âš¡ Worker Node 1<br/>172.17.176.35<br/>4 vCPU, 16GB RAM, 50GB]
            W2[âš¡ Worker Node 2<br/>172.17.176.36<br/>4 vCPU, 16GB RAM, 50GB]
        end
        
        subgraph "ğŸŒ ServiÃ§os de Rede"
            direction LR
            GW[Gateway: 172.17.176.1]
            DNS[DNS: 172.17.176.1, 8.8.4.4]
            BR[Bridge: vmbr0]
        end
    end
    
    subgraph "ğŸ›ï¸ Interfaces de Gerenciamento"
        RANCHER[ğŸ¤  Rancher UI<br/>:8443<br/>admin/admin123]
        KAPI[â˜¸ï¸ Kubernetes API<br/>:6443<br/>kubectl access]
    end
    
    DEV --> TF
    TF --> PVE
    DEV --> AN
    AN --> M1
    AN --> W1  
    AN --> W2
    PVE --> TPL
    TPL --> M1
    TPL --> W1
    TPL --> W2
    M1 --> RANCHER
    M1 --> KAPI
    GW --> M1
    GW --> W1
    GW --> W2
```

### ğŸ› ï¸ **Stack TecnolÃ³gico**

#### **ğŸ—ï¸ Camada de Infraestrutura**
- **Proxmox VE 7.0+**: Plataforma de virtualizaÃ§Ã£o empresarial
- **Terraform v1.0+**: Infraestrutura como cÃ³digo
- **Ubuntu 22.04 LTS**: Sistema operacional base com suporte atÃ© 2027
- **Cloud-init**: ConfiguraÃ§Ã£o automÃ¡tica de instÃ¢ncias

#### **âš™ï¸ Camada de ConfiguraÃ§Ã£o**  
- **Ansible v2.12+**: AutomaÃ§Ã£o de configuraÃ§Ã£o
- **SSH Keys**: AutenticaÃ§Ã£o segura sem senhas
- **Python 3.8+**: Runtime para mÃ³dulos Ansible

#### **â˜¸ï¸ Camada de OrquestraÃ§Ã£o**
- **Kubernetes v1.28.2**: Orquestrador de containers
- **kubeadm**: Ferramenta de bootstrap do cluster
- **kubelet**: Agente dos nÃ³s
- **kubectl**: Interface de linha de comando

#### **ğŸš¢ Camada de Containers**
- **Docker CE**: Runtime de containers
- **containerd**: Interface de runtime de containers
- **Flannel CNI**: Plugin de rede para pods

#### **ğŸ›ï¸ Camada de Gerenciamento**
- **Rancher v2.7.5+**: Interface web de gerenciamento
- **cert-manager**: Gerenciamento automÃ¡tico de certificados TLS
- **Helm**: Gerenciador de pacotes Kubernetes

## ğŸ¯ **EspecificaÃ§Ãµes Detalhadas**

### ï¿½ **ConfiguraÃ§Ã£o dos NÃ³s**

| Componente | EspecificaÃ§Ã£o | Valor | ObservaÃ§Ãµes |
|------------|---------------|--------|-------------|
| **Master Node** | IP fixo | `172.17.176.34` | Control plane + Rancher |
|  | vCPU | 4 cores | MÃ­nimo para control plane |
|  | RAM | 8GB | Recomendado para Rancher |
|  | Disco | 80GB | Sistema + etcd + containers |
|  | FunÃ§Ã£o | Control plane | API server, scheduler, etcd |
| **Worker Node 1** | IP fixo | `172.17.176.35` | Cargas de trabalho |
|  | vCPU | 4 cores | Balanceamento de carga |
|  | RAM | 16GB | Otimizado para workloads |
|  | Disco | 50GB | Containers e volumes |
|  | FunÃ§Ã£o | Worker | Executar pods de aplicaÃ§Ã£o |
| **Worker Node 2** | IP fixo | `172.17.176.36` | Cargas de trabalho |
|  | vCPU | 4 cores | RedundÃ¢ncia |
|  | RAM | 16GB | Otimizado para workloads |
|  | Disco | 50GB | Containers e volumes |
|  | FunÃ§Ã£o | Worker | Executar pods de aplicaÃ§Ã£o |

### ğŸŒ **ConfiguraÃ§Ã£o de Rede**

| ParÃ¢metro | Valor | DescriÃ§Ã£o |
|-----------|--------|-----------|
| **Subnet** | `172.17.176.0/20` | Rede institucional CEFETES |
| **Gateway** | `172.17.176.1` | Gateway padrÃ£o |
| **DNS Primary** | `172.17.176.1` | DNS institucional |
| **DNS Secondary** | `8.8.4.4` | DNS pÃºblico Google |
| **Search Domain** | `cefetes.br` | DomÃ­nio de busca |
| **Bridge** | `vmbr0` | Bridge de rede Proxmox |

### ğŸ·ï¸ **Sistema de Tags**

#### **Tags Comuns (Todos os Recursos)**
```yaml
environment: "production"           # Ambiente de execuÃ§Ã£o
project: "k8s-cluster-viana"       # Nome do projeto
managed-by: "terraform"            # Ferramenta de gestÃ£o
```

#### **Tags EspecÃ­ficas por Tipo**
```yaml
# Master nodes
kubernetes: true
master: true  
node-type: "control-plane"

# Worker nodes
kubernetes: true
worker: true
node-type: "worker"
```

### ğŸ” **ConfiguraÃ§Ã£o de SeguranÃ§a**

| Aspecto | ImplementaÃ§Ã£o | BenefÃ­cio |
|---------|---------------|-----------|
| **AutenticaÃ§Ã£o** | SSH Keys exclusivo | Sem senhas, mais seguro |
| **Chave SSH** | `~/.ssh/k8s-cluster-key` | Dedicada ao cluster |
| **UsuÃ¡rio VM** | `admviana` | UsuÃ¡rio administrativo |
| **Firewall** | Regras Proxmox + iptables | Controle de trÃ¡fego |
| **Certificados** | cert-manager + Let's Encrypt | TLS automÃ¡tico |
| **RBAC** | Kubernetes nativo | Controle de acesso granular |

### ğŸ“Š **Recursos Totais do Cluster**

| Recurso | Total | DistribuiÃ§Ã£o |
|---------|--------|--------------|
| **vCPUs** | 12 cores | 4 (master) + 4 (worker1) + 4 (worker2) |
| **RAM** | 40GB | 8GB (master) + 16GB (worker1) + 16GB (worker2) |
| **Storage** | 180GB | 80GB (master) + 50GB (worker1) + 50GB (worker2) |
| **IPs** | 3 fixos | Faixa 172.17.176.34-36 |

## ğŸš€ **Fluxo de ImplantaÃ§Ã£o**

### ğŸ“‹ **Processo Automatizado (make install)**

```mermaid
flowchart TD
    A[ğŸš€ make install] --> B[ğŸ“¦ Instalar Prerequisites]
    B --> C[ğŸ”§ Terraform Init]
    C --> D[ğŸ“Š Terraform Plan]
    D --> E[ğŸ—ï¸ Terraform Apply]
    E --> F[â° Aguardar VMs - 60s]
    F --> G[ğŸ¤– Ansible Execution]
    G --> H[âœ… Validar Cluster]
    
    subgraph "ğŸ—ï¸ Terraform Apply"
        E1[Criar VM Master]
        E2[Criar VM Worker 1]
        E3[Criar VM Worker 2]
        E4[Gerar InventÃ¡rio Ansible]
    end
    
    subgraph "ğŸ¤– Ansible Execution"
        G1[Preparar SO - Todos os nÃ³s]
        G2[Instalar Docker - Todos os nÃ³s]
        G3[Instalar Kubernetes - Todos os nÃ³s]
        G4[Configurar Master - kubeadm init]
        G5[Instalar Flannel CNI]
        G6[Join Workers ao Cluster]
        G7[Instalar cert-manager]
        G8[Instalar Rancher]
    end
    
    E --> E1
    E1 --> E2
    E2 --> E3
    E3 --> E4
    
    G --> G1
    G1 --> G2
    G2 --> G3
    G3 --> G4
    G4 --> G5
    G5 --> G6
    G6 --> G7
    G7 --> G8
```

### â±ï¸ **Timeline de ImplantaÃ§Ã£o**

| Fase | DuraÃ§Ã£o | DescriÃ§Ã£o | Status |
|------|---------|-----------|--------|
| **Prerequisites** | 2-3 min | Collections Ansible + Python packages | ğŸ”„ |
| **Terraform** | 5-8 min | CriaÃ§Ã£o das 3 VMs no Proxmox | ğŸ”„ |
| **InicializaÃ§Ã£o** | 1 min | Boot das VMs + cloud-init | â¸ï¸ |
| **Ansible Common** | 2-3 min | PreparaÃ§Ã£o SO + mÃ³dulos kernel | ğŸ”„ |
| **Docker Install** | 3-4 min | Docker + containerd em todos os nÃ³s | ğŸ”„ |
| **Kubernetes** | 4-5 min | kubeadm, kubelet, kubectl | ğŸ”„ |
| **Cluster Setup** | 2-3 min | Master init + worker join | ğŸ”„ |
| **Rancher** | 3-5 min | Helm + cert-manager + Rancher | ğŸ”„ |
| **ValidaÃ§Ã£o** | 1 min | Testes de conectividade | âœ… |
| **Total** | **15-20 min** | **Cluster completo funcionando** | âœ… |

### ğŸ”„ **Comandos por Fase**

#### **Fase 1: PreparaÃ§Ã£o**
```bash
make prerequisites  # Instala collections + Python packages
make init          # Inicializar Terraform backend
```

#### **Fase 2: Infraestrutura**  
```bash
make plan          # Revisar mudanÃ§as (opcional)
terraform apply    # Criar VMs + gerar inventÃ¡rio
```

#### **Fase 3: ConfiguraÃ§Ã£o**
```bash
cd ansible && ansible-playbook -i inventory site.yml
# Executa todas as roles: common â†’ docker â†’ kubernetes â†’ master â†’ worker â†’ rancher
```

#### **Fase 4: ValidaÃ§Ã£o**
```bash
make validate      # Testar cluster completo
make check         # VerificaÃ§Ã£o rÃ¡pida
```

## ğŸ“Š ConfiguraÃ§Ã£o PadrÃ£o (Rede GenÃ©rica)

| Componente | IP Fixo | Recursos |
|------------|---------|----------|
| **Master** | 192.168.1.10 | 4 vCPU, 8GB RAM, 80GB |
| **Worker 1** | 192.168.1.20 | 4 vCPU, 16GB RAM, 50GB |
| **Worker 2** | 192.168.1.21 | 4 vCPU, 16GB RAM, 50GB |

### ï¿½ï¸ Tags Aplicadas
# ğŸš€ VisÃ£o Geral: Cluster Kubernetes Empresarial no Proxmox VE

> **Projeto completo de Infraestrutura como CÃ³digo** para provisionar e gerenciar clusters Kubernetes de produÃ§Ã£o no Proxmox VE, utilizando as melhores prÃ¡ticas de automaÃ§Ã£o, seguranÃ§a e organizaÃ§Ã£o.

## ğŸ“‹ **Resumo Executivo**

Este projeto automatiza a criaÃ§Ã£o de uma infraestrutura completa de Kubernetes no Proxmox VE, desde o provisionamento das mÃ¡quinas virtuais atÃ© a configuraÃ§Ã£o de um cluster funcional com interface de gerenciamento Rancher, seguindo padrÃµes empresariais de seguranÃ§a e organizaÃ§Ã£o.

### ğŸ¯ **PropÃ³sito**
Fornecer uma soluÃ§Ã£o **turnkey** para organizaÃ§Ãµes que precisam de:
- Clusters Kubernetes **prontos para produÃ§Ã£o**
- **AutomaÃ§Ã£o completa** de deploy e configuraÃ§Ã£o
- **Interface moderna** de gerenciamento (Rancher)
- **Conformidade** com melhores prÃ¡ticas de seguranÃ§a
- **Flexibilidade** para diferentes ambientes e escalas

### ğŸ† **VersÃ£o Atual: v2.0 - Enterprise Ready**

#### âœ¨ **Principais Melhorias v2.0**
- ğŸ” **AutenticaÃ§Ã£o SSH** exclusiva com chaves dedicadas
- ğŸ·ï¸ **Sistema de tags** padronizado para gestÃ£o e billing
- âœ… **ValidaÃ§Ãµes robustas** que previnem configuraÃ§Ãµes inseguras
- ğŸ“Š **Outputs informativos** para facilitar o gerenciamento
- ğŸ›¡ï¸ **PrÃ¡ticas de seguranÃ§a** implementadas por padrÃ£o

## ğŸ” SeguranÃ§a

### ğŸ”‘ AutenticaÃ§Ã£o
- **SSH Keys** exclusivo (nÃ£o usa senhas)
- **Path configurÃ¡vel**: `~/.ssh/k8s-cluster-key`
- **Token API** Proxmox como variÃ¡vel sensÃ­vel

### âœ… ValidaÃ§Ãµes
- **Environment**: development/staging/production
- **Recursos**: MÃ­nimos garantidos
- **Counts**: Limites de nÃ³s (1-5 masters, 0-10 workers)
- **Paths**: ValidaÃ§Ã£o de extensÃµes

## ğŸ“ Estrutura Completa

```
terraform-proxmox-k8s/
â”œâ”€â”€ ğŸ—ï¸  Terraform (Infraestrutura)
â”‚   â”œâ”€â”€ main.tf                 # Recursos + locals + tags
â”‚   â”œâ”€â”€ variables.tf            # VariÃ¡veis + validaÃ§Ãµes
â”‚   â”œâ”€â”€ outputs.tf              # Outputs seguros
â”‚   â””â”€â”€ terraform.tfvars.example # ConfiguraÃ§Ã£o exemplo
â”‚
â”œâ”€â”€ ğŸ¤– Ansible (ConfiguraÃ§Ã£o)
â”‚   â”œâ”€â”€ site.yml                # Playbook principal
â”‚   â”œâ”€â”€ inventory.tpl           # Template inventÃ¡rio
â”‚   â”œâ”€â”€ ansible.cfg             # SSH key auth
â”‚   â”œâ”€â”€ requirements.yml        # DependÃªncias
â”‚   â”œâ”€â”€ group_vars/all.yml      # VariÃ¡veis globais
â”‚   â””â”€â”€ roles/                  # Roles de configuraÃ§Ã£o
â”‚       â”œâ”€â”€ common/             # Setup bÃ¡sico
â”‚       â”œâ”€â”€ docker/             # Docker + containerd
â”‚       â”œâ”€â”€ kubernetes/         # K8s base
â”‚       â”œâ”€â”€ kubernetes-master/  # Master config
â”‚       â”œâ”€â”€ kubernetes-worker/  # Worker config
â”‚       â””â”€â”€ rancher/            # Rancher install
â”‚
â”œâ”€â”€ ï¿½ Scripts Auxiliares
â”‚   â”œâ”€â”€ setup.sh               # Setup inicial
â”‚   â”œâ”€â”€ check-cluster.sh       # VerificaÃ§Ã£o
â”‚   â”œâ”€â”€ validate-cluster.sh    # ValidaÃ§Ã£o SSH key
â”‚   â””â”€â”€ create-template.sh     # Template automation
â”‚
â”œâ”€â”€ ğŸ› ï¸  AutomaÃ§Ã£o
â”‚   â”œâ”€â”€ Makefile               # Comandos + delay otimizado
â”‚   â””â”€â”€ .gitignore             # Arquivos ignorados
â”‚
â””â”€â”€ ğŸ“š DocumentaÃ§Ã£o
    â”œâ”€â”€ README.md              # DocumentaÃ§Ã£o principal
    â”œâ”€â”€ BEST-PRACTICES.md      # Melhores prÃ¡ticas
    â”œâ”€â”€ CHANGELOG.md           # Registro de mudanÃ§as
    â”œâ”€â”€ CLUSTER-QUICK-GUIDE.md # Guia rÃ¡pido
    â””â”€â”€ OVERVIEW.md            # Este arquivo
```

## âš¡ Comandos Principais

```bash
# === INSTALAÃ‡ÃƒO ===
make prerequisites     # Instalar dependÃªncias
make init             # Inicializar Terraform
make install          # InstalaÃ§Ã£o completa (com delay)
make plan             # Planejar mudanÃ§as

# === VERIFICAÃ‡ÃƒO ===
make check            # Status do cluster
make validate         # Validar configuraÃ§Ã£o
make status           # Status dos recursos

# === ACESSO ===
make ssh-master       # SSH no master
make ssh-worker-1     # SSH no worker 1
make get-kubeconfig   # Baixar kubeconfig

# === MANUTENÃ‡ÃƒO ===
make clean-ssh-keys   # Limpar known_hosts
make destroy          # Destruir infraestrutura
make clean            # Limpar temporÃ¡rios
```

## ğŸ¯ Casos de Uso

### ğŸ§ª **Desenvolvimento**
- Ambiente K8s local completo
- Testes de aplicaÃ§Ãµes containerizadas
- Experimentos com Rancher

### ğŸ« **LaboratÃ³rio/Educacional**
- Treinamento em Kubernetes
- Demos e apresentaÃ§Ãµes
- Ambiente de aprendizado
- SimulaÃ§Ã£o de ambientes produtivos

### ğŸ¢ **ProduÃ§Ã£o Small/Medium**
- Clusters pequenos/mÃ©dios
- Proof of Concepts
- Ambientes de staging
- Infraestrutura institucional

## ğŸš¨ PrÃ³ximos Passos apÃ³s InstalaÃ§Ã£o

1. **âœ… Verificar Status**: `make check`
2. **ğŸŒ Acessar Rancher**: https://SEU_MASTER_IP:8443
3. **ğŸ“‹ Baixar kubeconfig**: `make get-kubeconfig`
4. **ğŸš€ Deploy aplicaÃ§Ãµes**: Via Rancher UI ou kubectl
5. **ğŸ“Š Configurar monitoring**: Prometheus + Grafana
6. **ğŸ” Configurar RBAC**: UsuÃ¡rios e permissÃµes
7. **ğŸ’¾ EstratÃ©gia backup**: Volumes e configuraÃ§Ãµes

## ğŸ†˜ Troubleshooting

### ğŸ” **Logs Ãšteis**
```bash
# Cloud-init nas VMs
sudo cat /var/log/cloud-init-output.log

# Kubelet
sudo journalctl -u kubelet -f

# Rancher
kubectl logs -n cattle-system -l app=rancher

# Ansible detalhado
cd ansible && ansible-playbook -i inventory site.yml -vvv
```

### ğŸš‘ **Comandos de DiagnÃ³stico**
```bash
make status           # Status geral
make logs            # Logs de deployment
kubectl get nodes -o wide
kubectl get pods -A
```

---

âœ¨ **Enterprise Ready!** Seu cluster Kubernetes com Rancher seguro e bem organizado estÃ¡ pronto para produÃ§Ã£o!


## ğŸ“ Estrutura Completa

```
terraform-proxmox-k8s/
â”œâ”€â”€ ğŸ—ï¸  Terraform (Infraestrutura)
â”‚   â”œâ”€â”€ main.tf                 # Recursos principais
â”‚   â”œâ”€â”€ variables.tf            # VariÃ¡veis
â”‚   â”œâ”€â”€ outputs.tf              # Outputs
â”‚   â””â”€â”€ terraform.tfvars.example # ConfiguraÃ§Ã£o exemplo
â”‚
â”œâ”€â”€ ğŸ¤– Ansible (ConfiguraÃ§Ã£o)
â”‚   â”œâ”€â”€ site.yml                # Playbook principal
â”‚   â”œâ”€â”€ inventory.tpl           # Template inventÃ¡rio
â”‚   â”œâ”€â”€ ansible.cfg             # ConfiguraÃ§Ã£o Ansible
â”‚   â”œâ”€â”€ requirements.yml        # DependÃªncias
â”‚   â”œâ”€â”€ group_vars/all.yml      # VariÃ¡veis globais
â”‚   â””â”€â”€ roles/                  # Roles de configuraÃ§Ã£o
â”‚       â”œâ”€â”€ common/             # Setup bÃ¡sico
â”‚       â”œâ”€â”€ docker/             # Docker + containerd
â”‚       â”œâ”€â”€ kubernetes/         # K8s base
â”‚       â”œâ”€â”€ kubernetes-master/  # Master config
â”‚       â”œâ”€â”€ kubernetes-worker/  # Worker config
â”‚       â””â”€â”€ rancher/            # Rancher install
â”‚
â”œâ”€â”€ ğŸ“œ Scripts Auxiliares
â”‚   â”œâ”€â”€ setup.sh               # Setup inicial
â”‚   â”œâ”€â”€ check-cluster.sh       # VerificaÃ§Ã£o
â”‚   â””â”€â”€ deploy-example.sh      # Deploy exemplo
â”‚
â”œâ”€â”€ ğŸ› ï¸  AutomaÃ§Ã£o
â”‚   â”œâ”€â”€ Makefile               # Comandos automatizados
â”‚   â””â”€â”€ .gitignore             # Arquivos ignorados
â”‚
â””â”€â”€ ğŸ“š DocumentaÃ§Ã£o
    â”œâ”€â”€ README.md              # DocumentaÃ§Ã£o principal
    â””â”€â”€ terraform.tfvars.detailed # ConfiguraÃ§Ã£o detalhada
```

## âš¡ Comandos RÃ¡pidos

```bash
# Gerenciamento da infraestrutura
make init          # Inicializar Terraform
make plan          # Planejar mudanÃ§as
make apply         # Criar infraestrutura
make destroy       # Destruir tudo

# Gerenciamento do cluster
make check         # Verificar status
make ssh-master    # SSH no master
make get-kubeconfig # Baixar kubeconfig
make rancher-info  # Info do Rancher

# Ansible especÃ­fico
make ansible-setup # Instalar dependÃªncias
make ansible-run   # Executar playbooks

# Limpeza
make clean         # Limpar temporÃ¡rios
```

## ğŸ¯ **Casos de Uso**

### ğŸ¢ **Ambientes Empresariais**
- **Clusters de produÃ§Ã£o** para aplicaÃ§Ãµes crÃ­ticas
- **Ambientes de desenvolvimento** e homologaÃ§Ã£o  
- **MigraÃ§Ã£o** de aplicaÃ§Ãµes legadas para containers
- **ModernizaÃ§Ã£o** de infraestrutura com orquestraÃ§Ã£o

#### **BenefÃ­cios para Empresas:**
- âœ… **ReduÃ§Ã£o de custos** com infraestrutura
- âœ… **AutomaÃ§Ã£o** completa de deployment
- âœ… **Escalabilidade** horizontal automÃ¡tica  
- âœ… **Interface amigÃ¡vel** com Rancher
- âœ… **Conformidade** com padrÃµes de seguranÃ§a

### ğŸ« **InstituiÃ§Ãµes Educacionais**
- **LaboratÃ³rios** de ensino de Kubernetes
- **Pesquisa** em computaÃ§Ã£o distribuÃ­da
- **Treinamentos** e capacitaÃ§Ã£o profissional
- **Projetos** de fim de curso e pesquisa

#### **Vantagens Educacionais:**
- âœ… **Ambiente real** de produÃ§Ã£o
- âœ… **Aprendizado hands-on** completo
- âœ… **DocumentaÃ§Ã£o** pedagÃ³gica detalhada
- âœ… **Replicabilidade** para mÃºltiplos labs
- âœ… **Baixo custo** de implantaÃ§Ã£o

### ğŸ§ª **Desenvolvimento e Testes**
- **CI/CD pipelines** com Kubernetes nativo
- **Testes** de aplicaÃ§Ãµes em ambiente real  
- **Proof of Concepts** de novas tecnologias
- **ValidaÃ§Ã£o** de arquiteturas cloud-native

#### **Facilidades para DevOps:**
- âœ… **Deploy rÃ¡pido** de ambientes
- âœ… **ConfiguraÃ§Ã£o** versionada no Git
- âœ… **DestruiÃ§Ã£o** e recriaÃ§Ã£o simples
- âœ… **MÃºltiplos ambientes** (dev/staging/prod)
- âœ… **IntegraÃ§Ã£o** com ferramentas CI/CD

### ğŸ“Š **Comparativo de CenÃ¡rios**

| CenÃ¡rio | Tamanho | Recursos | Tempo Deploy | Complexidade |
|---------|---------|----------|--------------|--------------|
| **Lab Educacional** | 1 master + 2 workers | 40GB RAM total | 15 min | â­â­ |
| **Desenvolvimento** | 1 master + 3-5 workers | 64GB RAM total | 20 min | â­â­â­ |
| **Staging** | 3 masters + 5 workers | 128GB RAM total | 35 min | â­â­â­â­ |
| **ProduÃ§Ã£o Small** | 3 masters + 10 workers | 256GB RAM total | 45 min | â­â­â­â­â­ |

## ğŸ”§ **CustomizaÃ§Ã£o e Flexibilidade**

### ğŸ›ï¸ **ParÃ¢metros ConfigurÃ¡veis**

#### **Hardware dos NÃ³s**
```hcl
# ConfiguraÃ§Ãµes mÃ­nimas (lab)
master_memory = 4096    # 4GB RAM
worker_memory = 8192    # 8GB RAM
master_cpu = 2          # 2 vCPUs
worker_cpu = 2          # 2 vCPUs

# ConfiguraÃ§Ãµes otimizadas (produÃ§Ã£o)
master_memory = 16384   # 16GB RAM  
worker_memory = 32768   # 32GB RAM
master_cpu = 8          # 8 vCPUs
worker_cpu = 8          # 8 vCPUs
```

#### **Escala do Cluster**
```hcl
# Cluster pequeno (lab/dev)
master_count = 1
worker_count = 2

# Cluster mÃ©dio (staging)
master_count = 3
worker_count = 5

# Cluster grande (produÃ§Ã£o)
master_count = 3
worker_count = 10
```

#### **ConfiguraÃ§Ã£o de Rede**
```hcl
# Rede corporativa tÃ­pica
network_gateway = "10.0.0.1"
dns_servers = "10.0.0.1,8.8.8.8"
master_ips = ["10.0.0.10"]
worker_ips = ["10.0.0.20", "10.0.0.21"]

# Rede de laboratÃ³rio
network_gateway = "192.168.1.1"  
dns_servers = "192.168.1.1,8.8.4.4"
master_ips = ["192.168.1.100"]
worker_ips = ["192.168.1.101", "192.168.1.102"]
```

### ğŸŒ **Multi-Ambiente**

#### **ConfiguraÃ§Ã£o por Ambiente**
```bash
# Desenvolvimento
echo 'environment = "development"' >> terraform.tfvars
echo 'cluster_name = "k8s-dev"' >> terraform.tfvars

# Staging
echo 'environment = "staging"' >> terraform.tfvars  
echo 'cluster_name = "k8s-staging"' >> terraform.tfvars

# ProduÃ§Ã£o
echo 'environment = "production"' >> terraform.tfvars
echo 'cluster_name = "k8s-prod"' >> terraform.tfvars
```

### ğŸ”Œ **IntegraÃ§Ãµes DisponÃ­veis**

#### **Monitoramento**
- **Prometheus** + **Grafana** via Rancher Apps
- **AlertManager** para notificaÃ§Ãµes
- **Metrics Server** para HPA/VPA

#### **Storage**
- **Longhorn** para volumes distribuÃ­dos
- **NFS** para volumes compartilhados  
- **Local Path Provisioner** para desenvolvimento

#### **Networking**
- **MetalLB** para LoadBalancer services
- **Ingress-nginx** para ingress controller
- **Cert-manager** para certificados automÃ¡ticos

#### **CI/CD**
- **GitLab Runner** em Kubernetes
- **Jenkins** com agents dinÃ¢micos
- **ArgoCD** para GitOps
- **Tekton** para pipelines cloud-native

## ğŸ“š **PrÃ³ximos Passos e EvoluÃ§Ã£o**

### ï¿½ **ApÃ³s ImplantaÃ§Ã£o BÃ¡sica**

1. **âœ… Verificar Cluster**: `make validate`
2. **ğŸŒ Acessar Rancher**: `https://172.17.176.34:8443`
3. **ğŸ“‹ Configurar kubectl**: `make get-kubeconfig`
4. **ğŸš€ Deploy primeira aplicaÃ§Ã£o**: Via Rancher Apps
5. **ğŸ“Š Habilitar monitoring**: Prometheus + Grafana
6. **ğŸ” Configurar RBAC**: UsuÃ¡rios e permissÃµes
7. **ğŸ’¾ Implementar backup**: Longhorn ou external

### ğŸš€ **EvoluÃ§Ãµes Futuras**

#### **VersÃ£o 3.0 - HA & Multi-Node**
- **Masters HA**: 3 masters para alta disponibilidade
- **Load Balancer**: HAProxy ou MetalLB
- **Shared Storage**: NFS ou Ceph integration
- **Backup automatizado**: Velero integration

#### **VersÃ£o 4.0 - Multi-Cluster**  
- **Rancher Multi-Cluster**: Gerenciar mÃºltiplos clusters
- **Cluster Fleet**: GitOps para mÃºltiplos ambientes
- **Service Mesh**: Istio ou Linkerd
- **Advanced Monitoring**: Observability stack completo

### ğŸ“ˆ **MÃ©tricas de Sucesso**

| MÃ©trica | Meta | Atual |
|---------|------|-------|
| **Tempo de Deploy** | < 20 min | 15-20 min âœ… |
| **Uptime Cluster** | > 99.9% | A medir |
| **Tempo Recovery** | < 5 min | A implementar |
| **AutomaÃ§Ã£o** | 100% | 95% âœ… |
| **DocumentaÃ§Ã£o** | Completa | 90% âœ… |

---

## ğŸ‰ **ConclusÃ£o**

Este projeto representa uma **soluÃ§Ã£o completa e enterprise-ready** para implantaÃ§Ã£o de clusters Kubernetes no Proxmox VE, oferecendo:

### âœ¨ **Principais Diferenciais**

- ğŸ” **SeguranÃ§a por design** com SSH keys e validaÃ§Ãµes
- ğŸ·ï¸ **OrganizaÃ§Ã£o profissional** com tags e estrutura modular  
- ğŸ“– **DocumentaÃ§Ã£o pedagÃ³gica** completa e didÃ¡tica
- ğŸš€ **AutomaÃ§Ã£o total** do deploy Ã  validaÃ§Ã£o
- ğŸ”§ **Flexibilidade** para diferentes cenÃ¡rios de uso
- ğŸ›¡ï¸ **Melhores prÃ¡ticas** implementadas por padrÃ£o

### ğŸ¯ **Ideal Para**

- **ğŸ¢ Empresas** que precisam de Kubernetes on-premises
- **ğŸ« InstituiÃ§Ãµes educacionais** para ensino e pesquisa
- **ğŸ‘¨â€ğŸ’» Desenvolvedores** que querem ambiente real de K8s
- **ğŸ”¬ Pesquisadores** em computaÃ§Ã£o distribuÃ­da e cloud-native

### ğŸŒŸ **Resultado Final**

Um **cluster Kubernetes de produÃ§Ã£o** funcionando em menos de 20 minutos, com interface web moderna (Rancher), documentaÃ§Ã£o completa e flexibilidade para evoluir conforme necessÃ¡rio.

---

<div align="center">

**ğŸš€ Transforme sua infraestrutura com Kubernetes moderno!**

[![Feito com â¤ï¸ no CEFET-ES](https://img.shields.io/badge/Feito%20com%20â¤ï¸%20no-CEFET--ES-blue)](https://cefetes.br)

*Infraestrutura como CÃ³digo â€¢ Kubernetes â€¢ Rancher â€¢ Proxmox VE*

</div>

## ğŸš¨ PrÃ³ximos Passos apÃ³s InstalaÃ§Ã£o

1. **Configurar DNS**: Adicionar rancher.local ao /etc/hosts
2. **Explorar Rancher**: Interface web rica em funcionalidades
3. **Deploy aplicaÃ§Ãµes**: Usar catÃ¡logo do Rancher ou kubectl
4. **Configurar monitoring**: Prometheus + Grafana via Rancher
5. **Backup/Restore**: Configurar estratÃ©gias de backup
6. **SeguranÃ§a**: Configurar RBAC e polÃ­ticas de rede

## ğŸ†˜ Suporte

- **Issues**: Logs em `/var/log/cloud-init-output.log` nas VMs
- **Kubernetes**: `kubectl logs` e `journalctl -u kubelet`
- **Rancher**: Logs em namespace `cattle-system`
- **Ansible**: Execute com `-vvv` para debug detalhado

---

âœ¨ **Pronto para usar!** Seu cluster Kubernetes com Rancher estÃ¡ a apenas alguns comandos de distÃ¢ncia!
